大家下午好，这里是软2的施俣喆。今天给大家汇报一下我这一周的学习工作。还请各位多多指正！

本周我进行的学习主要有：

1. 搭建机器学习环境
2. 学习机器学习最基本的数学理论（梯度、信息论）
3. 尝试使用`pytorch`等库搭建了一个最简易的线性回归模型
4. 学习了`softmax`回归入门，正在编写图片分类的简单模型（但是还没弄好）。

PPT就不给大家献丑了，我就用文本给大家介绍。我采用了Markdown的形式来记录，使用Jupyter Notebook进行实验和保存实验记录。

梯度是深度学习最重要的概念之一。之后优化参数的方法正是由梯度得到。

这里是梯度的计算，运算法则以及我的一些证明。

这里是扩展到向量的求导法则。以及我的一些证明。

很多框架，比如，Pytorch也提供了自动微分的功能。



基于此，我们设计一个预测模型.

我们需要定义：

模型
评估损失函数
纠正损失的方法

运行模型。使用训练输入得到输出，根据损失函数评估损失，对损失函数求关于参数w的梯度，在参数调整中沿着梯度的反方向调整，能使损失函数尽可能的下降。

训练结束后使用测试数据集测试准确率。





softmax回归是另一种模型。与之前的线性回归输出连续的值不同的是，它用于解决离散的分类问题。

首先需要一些衡量概率相似度的概念，这里采用的是“交叉熵”，它能衡量同一事件的两个概率分布的相似度。也就是预测值与真实值的差距。

这是softmax函数本体。他把输出规范化为概率。